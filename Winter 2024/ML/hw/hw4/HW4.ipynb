{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define transforms\n",
    "transforms = transforms.Compose([transforms.Resize((32, 32)),\n",
    "                                 transforms.ToTensor()])\n",
    "\n",
    "# download and create datasets\n",
    "train_dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=True, \n",
    "                               transform=transforms,\n",
    "                               download=True)\n",
    "\n",
    "valid_dataset = datasets.MNIST(root='mnist_data', \n",
    "                               train=False, \n",
    "                               transform=transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(train_dataset[0]... cmap='gray')\n",
    "plt.text(10, -2, 'The label is ' + str(....))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper parameters\n",
    "RANDOM_SEED = 42\n",
    "LEARNING_RATE = 0.001\n",
    "BATCH_SIZE = 32\n",
    "N_EPOCHS = 15\n",
    "\n",
    "IMG_SIZE = 32\n",
    "N_CLASSES = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the data loaders\n",
    "train_loader = DataLoader(dataset=..., \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=...)\n",
    "\n",
    "valid_loader = DataLoader(dataset=..., \n",
    "                          batch_size=BATCH_SIZE, \n",
    "                          shuffle=...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def train(train_loader, model, criterion, optimizer):\n",
    "    '''\n",
    "    Train one epoch.\n",
    "    '''\n",
    "\n",
    "    model.train()\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in train_loader:\n",
    "\n",
    "        optimizer.....\n",
    "\n",
    "    \n",
    "        # Forward pass\n",
    "        y_hat, _ = model(X) \n",
    "        loss = ....\n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "        # Backward pass\n",
    "        .....\n",
    "        \n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    return model, optimizer, epoch_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(valid_loader, model, criterion):\n",
    "    '''\n",
    "    Function for the validation step of the training loop.\n",
    "    Returns the model and the loss on the test set.\n",
    "    '''\n",
    "   \n",
    "    model......\n",
    "    running_loss = 0\n",
    "    \n",
    "    for X, y_true in valid_loader:\n",
    "\n",
    "        # Forward pass and record loss\n",
    "        ...\n",
    "        \n",
    "        running_loss += loss.item() * X.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(valid_loader.dataset)\n",
    "        \n",
    "    return model, epoch_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(model, criterion, optimizer, train_loader, valid_loader, epochs, print_every=1):\n",
    "    '''\n",
    "    Function defining the entire training loop\n",
    "    '''\n",
    "    \n",
    "    # set objects for storing metrics\n",
    "    best_loss = 1e10\n",
    "    train_losses = []\n",
    "    valid_losses = []\n",
    "    train_accs = []\n",
    "    valid_accs = []\n",
    " \n",
    "    # Train model\n",
    "    for epoch in range(0, epochs):\n",
    "\n",
    "        # training\n",
    "        model, optimizer, train_loss = train(train_loader, model, criterion, optimizer)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # validation\n",
    "        with torch.no_grad():\n",
    "            model, valid_loss = validate(valid_loader, model, criterion)\n",
    "            valid_losses.append(valid_loss)\n",
    "\n",
    "        if epoch % print_every == (print_every - 1):\n",
    "            \n",
    "            train_acc = get_accuracy(model, train_loader,)\n",
    "            train_accs.append(train_acc)\n",
    "            valid_acc = get_accuracy(model, valid_loader)\n",
    "            valid_accs.append(valid_acc)\n",
    "                \n",
    "            print(f'{datetime.now().time().replace(microsecond=0)} '\n",
    "                  f'Epoch: {epoch}\\t'\n",
    "                  f'Train loss: {train_loss:.4f}\\t'\n",
    "                  f'Valid loss: {valid_loss:.4f}\\t'\n",
    "                  f'Train accuracy: {100 * train_acc:.2f}\\t'\n",
    "                  f'Valid accuracy: {100 * valid_acc:.2f}')\n",
    "    \n",
    "    performance = {\n",
    "        'train_losses':train_losses,\n",
    "        'valid_losses': valid_losses,\n",
    "        'train_acc': train_accs,\n",
    "        'valid_acc':valid_accs\n",
    "    }\n",
    "    \n",
    "    return model, optimizer, performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(model, data_loader):\n",
    "    '''\n",
    "    Function for computing the accuracy of the predictions over the entire data_loader\n",
    "    '''\n",
    "    \n",
    "    correct_pred = 0 \n",
    "    n = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model.....\n",
    "        for X, y_true in data_loader:\n",
    "\n",
    "            ....\n",
    "            ....\n",
    "\n",
    "            n += y_true.size(0)\n",
    "            correct_pred += (predicted_labels == y_true).sum()\n",
    "\n",
    "    return correct_pred.float() / n\n",
    "\n",
    "\n",
    "    \n",
    "def plot_performance(performance):\n",
    "    '''\n",
    "    Function for plotting training and validation losses\n",
    "    '''\n",
    "    \n",
    "    # temporarily change the style of the plots to seaborn \n",
    "    plt.style.use('seaborn')\n",
    "\n",
    "    fig, ax = plt.subplots(1, 2, figsize = (16, 4.5))\n",
    "    for key, value in performance.items():\n",
    "        if 'loss' in key:\n",
    "            ax[0].plot(value, label=key) \n",
    "        else:\n",
    "            ax[1].plot(value, label=key) \n",
    "    ax[0].set(title=\"Loss  over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss')\n",
    "    ax[1].set(title=\"accuracy over epochs\", \n",
    "            xlabel='Epoch',\n",
    "            ylabel='Loss')\n",
    "    ax[0].legend()\n",
    "    ax[1].legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # change the plot style to default\n",
    "    plt.style.use('default')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self, n_classes):\n",
    "        super(LeNet5, self).__init__()\n",
    "        \n",
    "    ....\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        ......\n",
    "        logits = self.classifier(x)\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "\n",
    "    def __init__(self, layers):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        ...\n",
    "\n",
    "    def forward(self, x):\n",
    "        ...\n",
    "        logits = ...\n",
    "        probs = F.softmax(logits, dim=1)\n",
    "        return logits, probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "\n",
    "model = LeNet5(N_CLASSES)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, performance_1 = training_loop(model, criterion, optimizer, train_loader, valid_loader, N_EPOCHS)\n",
    "plot_performance(performance_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(performance_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(RANDOM_SEED)\n",
    "layers = [1024, 256, 64, 16, N_CLASSES]\n",
    "model = MLP(layers)\n",
    "print(model)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, optimizer, performance_2 = training_loop(model, criterion, optimizer, train_loader, valid_loader, N_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_performance(performance_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
