{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled1.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "343a69e4d00f47d4b7225e52d0b569c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3008e83ef23946549b0953868f463e39",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dac5f7019e9b4a6197bbfddead7b41a2",
              "IPY_MODEL_a3efabba5d9f408c9fd7d90179fbb809"
            ]
          }
        },
        "3008e83ef23946549b0953868f463e39": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dac5f7019e9b4a6197bbfddead7b41a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_1b1e06e58ca740a3a2f795de6fcaea27",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "info",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d654583abc07486b8124a9ef8a11aa78"
          }
        },
        "a3efabba5d9f408c9fd7d90179fbb809": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_518f8c218af64cd3bc1bc0aee0ea8651",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:19&lt;00:00, 102515842.30it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_62f48dd3fbad4cb5be1dd1131efd2987"
          }
        },
        "1b1e06e58ca740a3a2f795de6fcaea27": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d654583abc07486b8124a9ef8a11aa78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "518f8c218af64cd3bc1bc0aee0ea8651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "62f48dd3fbad4cb5be1dd1131efd2987": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7906ccdd26240258cf4e935fb62bb0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0f66f60cfbe1441784f99f8985ed7144",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2eaec9e517b6439c831b5892cdb8ae56",
              "IPY_MODEL_71633aa2323c4f878a1f26c5fca2de40"
            ]
          }
        },
        "0f66f60cfbe1441784f99f8985ed7144": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2eaec9e517b6439c831b5892cdb8ae56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44d3a25827e74a93bc274eda0fa5f01e",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 46827520,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 46827520,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_72273c9069064435993d50f27b7ba14f"
          }
        },
        "71633aa2323c4f878a1f26c5fca2de40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f8e3102d79414c4c9453825f8e453638",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 44.7M/44.7M [00:00&lt;00:00, 54.7MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fc2b92ce9f6447768f3ee8d508522c67"
          }
        },
        "44d3a25827e74a93bc274eda0fa5f01e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "72273c9069064435993d50f27b7ba14f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f8e3102d79414c4c9453825f8e453638": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fc2b92ce9f6447768f3ee8d508522c67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/xhxuciedu/cs273p/blob/main/pytorch-tutorial.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FKQCFzXDnGH"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pylab as plt\n",
        "import sys\n",
        "import torch \n",
        "import torchvision\n",
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iw_f9layCouO"
      },
      "source": [
        "from IPython.display import HTML, display\n",
        "def set_default(figsize=(8, 5), dpi=100):\n",
        "    plt.style.use(['dark_background', 'bmh'])\n",
        "    plt.rc('axes', facecolor='k')\n",
        "    plt.rc('figure', facecolor='k')\n",
        "    plt.rc('figure', figsize=figsize, dpi=dpi)\n",
        "\n",
        "set_default()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_w92gMaP6N1"
      },
      "source": [
        "### Check Package Versions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uYr2YRtWPkel",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e3d36c-75e0-4647-82ee-63b16863ee43"
      },
      "source": [
        "print('__Python VERSION:', sys.version)\n",
        "print('__PyTorch VERSION:', torch.__version__)\n",
        "print('__CUDNN VERSION:', torch.backends.cudnn.version())\n",
        "print('__Number CUDA Devices:', torch.cuda.device_count())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "__Python VERSION: 3.7.10 (default, Feb 20 2021, 21:17:23) \n",
            "[GCC 7.5.0]\n",
            "__PyTorch VERSION: 1.7.1+cu101\n",
            "__CUDNN VERSION: 7603\n",
            "__Number CUDA Devices: 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eq_6EZ0QM23"
      },
      "source": [
        "### PyTorch\n",
        "What is PyTorch?\n",
        "\n",
        "It’s a Python based scientific computing package targeted at two sets of audiences:\n",
        "\n",
        "* A replacement for numpy to use the power of GPUs\n",
        "* a deep learning research platform that provides maximum flexibility and speed\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSa2TTQfQ3nS"
      },
      "source": [
        "### Tensors\n",
        "\n",
        "Tensors are similar to numpy’s ndarrays, with the addition being that Tensors can also be used on a GPU to accelerate computing.\n",
        "\n",
        "\n",
        "Construct a 5x3 matrix, uninitialized"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xTW9C9zVRLWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c79af034-3894-4d11-e128-e3220e77227c"
      },
      "source": [
        "x = torch.Tensor(5, 3)\n",
        "print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.3165e+14,  3.0851e-41,  1.3593e-43],\n",
            "        [ 1.5975e-43,  1.3593e-43,  1.5274e-43],\n",
            "        [ 1.6115e-43,  6.4460e-44,  1.3873e-43],\n",
            "        [ 1.4994e-43,  1.5695e-43,  1.6255e-43],\n",
            "        [ 0.0000e+00,  0.0000e+00,  3.4548e-09]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i74pPBySRRDZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0d20944-4bad-416a-e74d-7f759dc86fd2"
      },
      "source": [
        "# get its size\n",
        "y = torch.rand(5, 3)\n",
        "print(x + y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-2.3165e+14,  5.9685e-01,  5.3644e-01],\n",
            "        [ 9.5369e-01,  5.4011e-01,  8.1075e-01],\n",
            "        [ 2.0064e-01,  7.7589e-01,  4.1524e-02],\n",
            "        [ 3.7451e-01,  4.1807e-01,  1.3328e-01],\n",
            "        [ 4.0639e-01,  7.4064e-01,  8.0764e-01]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O0xeSB-3Rd1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38cd4b2d-6a08-499a-a856-5cbdaaa2df44"
      },
      "source": [
        "# Addition: in-place\n",
        "y.add_(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-2.3165e+14,  5.9685e-01,  5.3644e-01],\n",
              "        [ 9.5369e-01,  5.4011e-01,  8.1075e-01],\n",
              "        [ 2.0064e-01,  7.7589e-01,  4.1524e-02],\n",
              "        [ 3.7451e-01,  4.1807e-01,  1.3328e-01],\n",
              "        [ 4.0639e-01,  7.4064e-01,  8.0764e-01]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QagJi5H9YT_M"
      },
      "source": [
        "### Create tensors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zF881O3lYfwc"
      },
      "source": [
        "# random\n",
        "v = torch.rand(2, 3)            # Initialize with random number (uniform distribution)\n",
        "v = torch.randn(2, 3)           # With normal distribution (SD=1, mean=0)\n",
        "v = torch.randperm(4)   \n",
        "\n",
        "# ones\n",
        "eye = torch.eye(3)              # Create an identity 3x3 tensor\n",
        "v = torch.ones(10)              # A tensor of size 10 containing all ones\n",
        "v = torch.ones(2, 1, 2, 1)      # Size 2x1x2x1\n",
        "v = torch.ones_like(eye)        # A tensor with same shape as eye. Fill it with 1.\n",
        "\n",
        "# zeros\n",
        "v = torch.zeros(10) \n",
        "\n",
        "# range of values\n",
        "v = torch.arange(5)             # similar to range(5) but creating a Tensor\n",
        "v = torch.arange(0, 5, step=1)  # Size 5. Similar to range(0, 5, 1)\n",
        "\n",
        "# linear or log scale\n",
        "v = torch.linspace(1, 10, steps=10) # Create a Tensor with 10 linear points for (1, 10) inclusively\n",
        "v = torch.logspace(start=-10, end=10, steps=5) # Size 5: 1.0e-10 1.0e-05 1.0e+00, 1.0e+05, 1.0e+10"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j0_vX6QFbP9r"
      },
      "source": [
        "### Dot product, component-wide product, matrix multiplication, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hbf5A2rTYonK"
      },
      "source": [
        "# Dot product of 2 tensors\n",
        "r = torch.dot(torch.Tensor([4, 2]), torch.Tensor([3, 1])) # 14"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F-AZEEfEYosW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb6f37fd-e9d9-47dd-b7eb-23eadaedc526"
      },
      "source": [
        "# component-wise product\n",
        "torch.Tensor([4, 2])* torch.Tensor([3, 1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([12.,  2.])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnfFZpz4a0JG"
      },
      "source": [
        "# Matrix x Matrix\n",
        "# Size 2x4\n",
        "mat1 = torch.randn(2, 3)\n",
        "mat2 = torch.randn(3, 4)\n",
        "r = torch.mm(mat1, mat2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fNQ8Aw-ahBH"
      },
      "source": [
        "# Batch Matrix x Matrix\n",
        "# Size 10x3x5\n",
        "batch1 = torch.randn(10, 3, 4)\n",
        "batch2 = torch.randn(10, 4, 5)\n",
        "r = torch.bmm(batch1, batch2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zygHVhSba0eN"
      },
      "source": [
        "###Squeeze and unsqueeze"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vylLWkFfaicW"
      },
      "source": [
        "t = torch.ones(2,1,2,1) # Size 2x1x2x1\n",
        "r = torch.squeeze(t)     # Size 2x2\n",
        "r = torch.squeeze(t, 1)  # Squeeze dimension 1: Size 2x2x1\n",
        "\n",
        "# Un-squeeze a dimension\n",
        "x = torch.Tensor([1, 2, 3])\n",
        "r = torch.unsqueeze(x, 0)       # Size: 1x3\n",
        "r = torch.unsqueeze(x, 1)       # Size: 3x1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6gEsNF3a-26"
      },
      "source": [
        "### Transpose\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwCePtvPa_hO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa870231-ae05-4485-d4d6-46501ff28f6a"
      },
      "source": [
        "# Transpose dim 0 and 1\n",
        "v = torch.randn(3,2)\n",
        "r = torch.transpose(v, 0, 1)\n",
        "print(r.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6wj7JQJRna5"
      },
      "source": [
        "### Numpy Bridge\n",
        "Converting a torch Tensor to a numpy array and vice versa is a breeze.\n",
        "\n",
        "The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other.\n",
        "\n",
        "Converting torch Tensor to numpy Array"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M-V3P-KeOdFY"
      },
      "source": [
        "# Create a numpy array.\n",
        "x = np.array([[1, 2], [3, 4]])\n",
        "\n",
        "# Convert the numpy array to a torch tensor.\n",
        "y = torch.from_numpy(x)\n",
        "\n",
        "# Convert the torch tensor to a numpy array.\n",
        "z = y.numpy()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DrxFA9zrOhcw"
      },
      "source": [
        "# Conversion\n",
        "a = np.array([1, 2, 3])\n",
        "v = torch.from_numpy(a)         # Convert a numpy array to a Tensor\n",
        "\n",
        "b = v.numpy()                   # Tensor to numpy\n",
        "b[1] = -1                       # Numpy and Tensor share the same memory\n",
        "assert(a[1] == b[1])            # Change Numpy will also change the Tensor"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkrFAPSzYDLa"
      },
      "source": [
        "### Reshape tensor"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVJAK82AYB78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb7bc9b-b6ba-4d17-a2e9-180a2cf00f17"
      },
      "source": [
        "### Tensor resizing\n",
        "x = torch.randn(2, 3)            # Size 2x3\n",
        "y = x.view(6)                    # Resize x to size 6\n",
        "z = x.view(-1, 2)                # Size 3x2\n",
        "print(y.shape, z.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([6]) torch.Size([3, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfoEcojSYTra"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CJnuUJgeSH5S"
      },
      "source": [
        "###CUDA Tensors\n",
        "\n",
        "All the Tensors on the CPU except a CharTensor support converting to NumPy and back.\n",
        "\n",
        "\n",
        "Tensors can be moved onto GPU using the .cuda function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPUVPxqbSP_8"
      },
      "source": [
        "# let us run this cell only if CUDA is available\n",
        "\n",
        "x = torch.rand(3,2)\n",
        "y = torch.rand(3,2)\n",
        "if torch.cuda.is_available():\n",
        "    x = x.cuda()\n",
        "    y = y.cuda()\n",
        "    x + y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUYQkqCUSiRT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd26dbe-1dd3-4b0b-bfd1-59849f378229"
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.2339, 0.4187],\n",
              "        [0.9977, 0.7115],\n",
              "        [0.2129, 0.9028]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N20kEqktSQKm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1c3de1c-829a-4d3c-87a6-202957b4c985"
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.1377, 0.7796],\n",
              "        [0.2557, 0.0923],\n",
              "        [0.3180, 0.3689]], device='cuda:0')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1mS3kiy9UNoR"
      },
      "source": [
        "## Autograd: automatic differentiation\n",
        "\n",
        "Central to all neural networks in PyTorch is autograd, a core torch package for automatic differentiation. \n",
        "\n",
        "\n",
        "The autograd package provides automatic differentiation for all operations on Tensors. It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different.\n",
        "\n",
        "Let us see this in more simple terms with some examples."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PmxgzX_6U4rn"
      },
      "source": [
        "# create an variable\n",
        "x = torch.ones((2,2), requires_grad=True)\n",
        "\n",
        "# Do an operation of variable:\n",
        "y = x + 2\n",
        "\n",
        "# Do more operations on y\n",
        "z = y * y * 3\n",
        "out = z.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdNxo2rxU4zr"
      },
      "source": [
        "# Gradients\n",
        "# ---------\n",
        "# let's backprop now\n",
        "# ``out.backward()`` is equivalent to doing ``out.backward(torch.Tensor([1.0]))``\n",
        "out.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UNK-RRBmU43f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1d7a184-4d47-4e84-d255-21c6bf895fd5"
      },
      "source": [
        "###############################################################\n",
        "# print gradients d(out)/dx\n",
        "#\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VUDiTPCeWGlU"
      },
      "source": [
        "You should have got a matrix of ``4.5``. Let’s call the ``out`` *Variable* $o$.\n",
        "We have that: $o = \\frac{1}{4}\\sum_i z_i$, \n",
        "$z_i = 3(x_i+2)^2$ and $z_i\\bigr\\rvert_{x_i=1} = 27$\n",
        "\n",
        "Therefore,\n",
        "$$\\frac{\\partial o}{\\partial x_i} = \\frac{3}{2}(x_i+2)$$ hence\n",
        "$$\\frac{\\partial o}{\\partial x_i}\\bigr\\rvert_{x_i=1} = \\frac{9}{2} = 4.5$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKL_ex-DWs_L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a497edab-d53b-40de-8c87-21cd77af7c07"
      },
      "source": [
        "# You can do many crazy things with autograd!\n",
        "x = torch.randn(3, requires_grad=True)\n",
        "\n",
        "y = x * 2\n",
        "while y.data.norm() < 1000:\n",
        "    y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1011.5469,   212.4474,   499.2918], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmSVgbJNWyqu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc612723-e108-4b1d-a8b4-b6eb8ff09840"
      },
      "source": [
        "gradients = torch.FloatTensor([0.1, 1.0, 0.0001])\n",
        "y.backward(gradients)\n",
        "\n",
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQ5oVt1kFv6N"
      },
      "source": [
        "### Basic autograd example 1 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx-5ce4DE2y-"
      },
      "source": [
        "# Create tensors.\n",
        "x = torch.tensor(1., requires_grad=True)\n",
        "w = torch.tensor(2., requires_grad=True)\n",
        "b = torch.tensor(3., requires_grad=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mcy6p4nSE5Yt"
      },
      "source": [
        "# Build a computational graph.\n",
        "y = w * x + b    # y = 2 * x + 3"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gzfF4EDBGyJB"
      },
      "source": [
        "# Compute gradients.\n",
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i3hIZDh1GrJn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40957869-de53-4e8c-90c4-d4c3d7228917"
      },
      "source": [
        "# Print out the gradients.\n",
        "print(x.grad)    # x.grad = 2 \n",
        "print(w.grad)    # w.grad = 1 \n",
        "print(b.grad)    # b.grad = 1 "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(2.)\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiS-D364E6JC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "719d6344-6fc0-49bf-8c91-4f5d1185aa97"
      },
      "source": [
        "y.detach().numpy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(5., dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ahapqf3VF8Fn"
      },
      "source": [
        "### Basic autograd example 2  "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgah0xn0GCxA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "169a0d08-8072-4300-cf91-8625e4e51aeb"
      },
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "print(x.shape, y.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([10, 3]) torch.Size([10, 2])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiQkdoJXGLeJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fd12f083-fbbf-49d2-d366-39d1e9a22341"
      },
      "source": [
        "# Build a fully connected layer.\n",
        "linear = nn.Linear(3, 2)\n",
        "print ('w: ', linear.weight)\n",
        "print ('b: ', linear.bias)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w:  Parameter containing:\n",
            "tensor([[-0.3580, -0.1151,  0.0306],\n",
            "        [-0.2708,  0.2443, -0.1761]], requires_grad=True)\n",
            "b:  Parameter containing:\n",
            "tensor([ 0.0616, -0.2742], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IvOuGobUG_c4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a039f7b-fba4-4968-e115-1f71236d2349"
      },
      "source": [
        "loss = torch.sum((linear(x)-y)**2)/y.shape[0]\n",
        "print('loss: ', loss.data.numpy())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  1.0595618\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Jg-jZqxIswR"
      },
      "source": [
        "loss.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIJ9YkofIszl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4af6020-8e55-4187-c0df-2abd1b36fa93"
      },
      "source": [
        "print('w grad: ', linear.weight.grad)\n",
        "print('b grad: ', linear.bias.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad:  tensor([[-1.0422,  0.0540,  0.2493],\n",
            "        [-0.2615, -0.4281,  0.1976]])\n",
            "b grad:  tensor([ 0.7455, -0.4274])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPtT7MCXJJsj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14575b6b-a99d-4d07-82c7-20673e4372f0"
      },
      "source": [
        "# check grad\n",
        "print('w grad:', (linear(x)-y).transpose(0,1).mm(x)/y.shape[0]*2)\n",
        "print('b grad:', 2*torch.mean(linear(x)-y, dim=0))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "w grad: tensor([[-1.0422,  0.0540,  0.2493],\n",
            "        [-0.2615, -0.4281,  0.1976]], grad_fn=<MulBackward0>)\n",
            "b grad: tensor([ 0.7455, -0.4274], grad_fn=<MulBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yy7Cv9ugMN0K"
      },
      "source": [
        "###. Basic autograd example 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hon-LU88MN6L"
      },
      "source": [
        "# Create tensors of shape (10, 3) and (10, 2).\n",
        "x = torch.randn(10, 3)\n",
        "y = torch.randn(10, 2)\n",
        "linear = nn.Linear(3, 2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ltmT6QfoFMal",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "701866de-8f60-44b9-fc55-67699b152bf1"
      },
      "source": [
        "# Build loss function and optimizer.\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = torch.optim.SGD(linear.parameters(), lr=0.01)\n",
        "\n",
        "# Forward pass.\n",
        "pred = linear(x)\n",
        "\n",
        "# Compute loss.\n",
        "loss = criterion(pred, y)\n",
        "print('loss: ', loss.item())\n",
        "\n",
        "# Backward pass.\n",
        "loss.backward()\n",
        "\n",
        "# Print out the gradients.\n",
        "print ('dL/dw: ', linear.weight.grad) \n",
        "print ('dL/db: ', linear.bias.grad)\n",
        "\n",
        "# 1-step gradient descent.\n",
        "optimizer.step()\n",
        "\n",
        "# You can also perform gradient descent at the low level.\n",
        "# linear.weight.data.sub_(0.01 * linear.weight.grad.data)\n",
        "# linear.bias.data.sub_(0.01 * linear.bias.grad.data)\n",
        "\n",
        "# Print out the loss after 1-step gradient descent.\n",
        "pred = linear(x)\n",
        "loss = criterion(pred, y)\n",
        "print('loss after 1 step optimization: ', loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "loss:  1.1785218715667725\n",
            "dL/dw:  tensor([[ 0.7789,  0.2582,  0.5103],\n",
            "        [-0.4900, -0.2236,  0.0021]])\n",
            "dL/db:  tensor([-0.6611,  0.5150])\n",
            "loss after 1 step optimization:  1.1594419479370117\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WO2btHYRjJ6D"
      },
      "source": [
        "## Input pipeline, Data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC-xoV6kPmlm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118,
          "referenced_widgets": [
            "343a69e4d00f47d4b7225e52d0b569c9",
            "3008e83ef23946549b0953868f463e39",
            "dac5f7019e9b4a6197bbfddead7b41a2",
            "a3efabba5d9f408c9fd7d90179fbb809",
            "1b1e06e58ca740a3a2f795de6fcaea27",
            "d654583abc07486b8124a9ef8a11aa78",
            "518f8c218af64cd3bc1bc0aee0ea8651",
            "62f48dd3fbad4cb5be1dd1131efd2987"
          ]
        },
        "outputId": "87509b8e-8251-4f84-c04e-8012d17e8190"
      },
      "source": [
        "# # Download and construct CIFAR-10 dataset.\n",
        "# train_dataset = torchvision.datasets.CIFAR10(root='../../data/',\n",
        "#                                              train=True, \n",
        "#                                              transform=transforms.ToTensor(),\n",
        "#                                              download=True)\n",
        "\n",
        "# # Fetch one data pair (read data from disk).\n",
        "# image, label = train_dataset[0]\n",
        "# print (image.size())\n",
        "# print (label)\n",
        "\n",
        "# # Data loader (this provides queues and threads in a very simple way).\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "#                                            batch_size=64, \n",
        "#                                            shuffle=True)\n",
        "\n",
        "# # When iteration starts, queue and thread start to load data from files.\n",
        "# data_iter = iter(train_loader)\n",
        "\n",
        "# # Mini-batch images and labels.\n",
        "# images, labels = data_iter.next()\n",
        "\n",
        "# # Actual usage of the data loader is as below.\n",
        "# for images, labels in train_loader:\n",
        "#     # Training code should be written here.\n",
        "#     pass"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../../data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "343a69e4d00f47d4b7225e52d0b569c9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ../../data/cifar-10-python.tar.gz to ../../data/\n",
            "torch.Size([3, 32, 32])\n",
            "6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bI16kN0tjnRl"
      },
      "source": [
        "### Input pipeline for custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLfA6_yGjlwF"
      },
      "source": [
        "# # ================================================================== #\n",
        "# #                  Input pipeline for custom dataset                 #\n",
        "# # ================================================================== #\n",
        "\n",
        "# # You should build your custom dataset as below.\n",
        "# class CustomDataset(torch.utils.data.Dataset):\n",
        "#     def __init__(self):\n",
        "#         # TODO\n",
        "#         # 1. Initialize file paths or a list of file names. \n",
        "#         pass\n",
        "#     def __getitem__(self, index):\n",
        "#         # TODO\n",
        "#         # 1. Read one data from file (e.g. using numpy.fromfile, PIL.Image.open).\n",
        "#         # 2. Preprocess the data (e.g. torchvision.Transform).\n",
        "#         # 3. Return a data pair (e.g. image and label).\n",
        "#         pass\n",
        "#     def __len__(self):\n",
        "#         # You should change 0 to the total size of your dataset.\n",
        "#         return 0 \n",
        "\n",
        "# # You can then use the prebuilt data loader. \n",
        "# custom_dataset = CustomDataset()\n",
        "# train_loader = torch.utils.data.DataLoader(dataset=custom_dataset,\n",
        "#                                            batch_size=64, \n",
        "#                                            shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "olrd4PlTjgv7"
      },
      "source": [
        "### Pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRsDNLcKjfGz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "a7906ccdd26240258cf4e935fb62bb0f",
            "0f66f60cfbe1441784f99f8985ed7144",
            "2eaec9e517b6439c831b5892cdb8ae56",
            "71633aa2323c4f878a1f26c5fca2de40",
            "44d3a25827e74a93bc274eda0fa5f01e",
            "72273c9069064435993d50f27b7ba14f",
            "f8e3102d79414c4c9453825f8e453638",
            "fc2b92ce9f6447768f3ee8d508522c67"
          ]
        },
        "outputId": "071ea4e0-b00c-4e76-f6cc-16b4eaed781b"
      },
      "source": [
        "# # ================================================================== #\n",
        "# #                           Pretrained model                         #\n",
        "# # ================================================================== #\n",
        "\n",
        "# # Download and load the pretrained ResNet-18.\n",
        "# resnet = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "# # If you want to finetune only the top layer of the model, set as below.\n",
        "# for param in resnet.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# # Replace the top layer for finetuning.\n",
        "# resnet.fc = nn.Linear(resnet.fc.in_features, 100)  # 100 is an example.\n",
        "\n",
        "# # Forward pass.\n",
        "# images = torch.randn(64, 3, 224, 224)\n",
        "# outputs = resnet(images)\n",
        "# print (outputs.size())     # (64, 100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a7906ccdd26240258cf4e935fb62bb0f",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "torch.Size([64, 100])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9VbbrBlBjY6P"
      },
      "source": [
        "### Save and load the model    "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfYBD7T_jW6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f3de4594-d51b-45f8-8a2f-94f95a5ae74f"
      },
      "source": [
        "# # Save and load the entire model.\n",
        "# torch.save(resnet, 'model.ckpt')\n",
        "# model = torch.load('model.ckpt')\n",
        "\n",
        "# # Save and load only the model parameters (recommended).\n",
        "# torch.save(resnet.state_dict(), 'params.ckpt')\n",
        "# resnet.load_state_dict(torch.load('params.ckpt'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx1gFIdtjdcE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}