{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this Notebook is to help you understand better what SVD is doing. This is in addition to the class slides.\n",
    "\n",
    "We will start with simple Geometric example that will help visualise the learned model, switch to quick review of the HW assignment and show how those things can be applied there and finish with an example of real-life application use in recommender systems "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "from __future__ import division # For python 2.*\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import mltools as ml\n",
    "\n",
    "# Importing SVD\n",
    "from scipy.linalg import svd\n",
    "\n",
    "np.random.seed(0)\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Geomtric Example\n",
    "\n",
    "The idea of SVD is based on geometric properties. If you don't remember much from linear algebra let's try and refresh your memory with a simple 2-dimensional data. \n",
    "\n",
    "What SVD is doing is finding principal components that are orthogonal basis functions. This means that in this 2d example we are going to find two vectors that can represent any point as a linear combination of those points.\n",
    "\n",
    "The two basis-functions (also known as directions) that SVD will find will be the ones that will preserve the data relation the most in the embedded space (we'll get to that in few code blocks).\n",
    "\n",
    "Let's look at the following example.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sampling a 400 points from a 2-dimensional gaussian distribution with an eliptic slented shape.\n",
    "ps = np.random.multivariate_normal([0, 0], [[3, 2.5], [2.5, 3.2]], size=400)\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=120, alpha=.75)\n",
    "\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here in this exampel we have 400 points in the plane. The idea of representing the points in an embedded space (also known as latent-space) is not new to you. This is the same whing that K-Means clustering is doing. In that K-Means each centroid (or cluster) is a dimension in that space and the points are now represented by the centroids.\n",
    "\n",
    "The difference is that SVD finds \"directions\" instead of spatial clusters. So let's run SVD and see what it finds."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running SVD\n",
    "The process for running SVD is almost exactly the same every time:\n",
    "\n",
    "1. Remove the mean from the data (to scale it).\n",
    "2. Find the U, s, V using the SVD algorithm with the parameter full_matrices set to False.\n",
    "3. Combine U and s into W."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "mu = np.mean(ps, axis=0)\n",
    "X0 = ps - mu\n",
    "\n",
    "# Step 2\n",
    "U, s, V = svd(X0, full_matrices=False)\n",
    "\n",
    "# Step 3\n",
    "W = np.dot(U, np.diag(s))\n",
    "\n",
    "print ('Shape of W = (%d, %d)' % W.shape, 'Shape of V = (%d, %d)' % V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of V\n",
    "The learned V matrix is the directions that the SVD finds (or the principle components). It represents for us the new latent-space in which each row is a unique direction.\n",
    "\n",
    "In the HW assignment you are required to plot the directions for the Faces data sets, and there's a code that shows you how to do that. Using that code on the 2-D example results in the following plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=80, alpha=.55)\n",
    "\n",
    "for j in range(2):\n",
    "    a = 2 * np.median(np.abs(W[:, j]))  # The scalar\n",
    "\n",
    "    # Compting the \"direction\" as a function of the mean.\n",
    "    p1 = mu - a * V[j]\n",
    "    p2 = mu + a * V[j]\n",
    "    \n",
    "    dx, dy = p2 - p1\n",
    "    ax.arrow(p1[0], p1[1], dx, dy, head_width=0.5, head_length=0.5, lw=3, \n",
    "             ec='purple', fc='darkgreen')\n",
    "\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that running SVD gave us two orthogonal lines (basis functions),  each one of them is a \"direction\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding W\n",
    "Each row in V is a basis function, and each point can be represented as a linear combination of those basis function. The scalar used in that linear combination are in W.\n",
    "\n",
    "If we take the first point (0 index) in X table as an example, each entry can be represented as a dot product of the first row in W and the corresponding column in V:\n",
    "\n",
    "$$X_{00} = W_{00} V_{00} + W_{01} V_{10}$$\n",
    "\n",
    "So W gives us the coordinates of each point in the new space defined by V.\n",
    "\n",
    "That means that we can get all the points back by simply doing the dot product of W and V (DO NOT FORGET TO ADD THE MU BACK -- SEE NOTES IN CODE)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=80, alpha=.55)\n",
    "\n",
    "# Reconstruction of the data from the latent-space representation\n",
    "Xhat = np.dot(W, V) + mu # DO NOT FORGET TO ADD BACK THE MU\n",
    "\n",
    "# Plotting the reconstructed points on top of the blue dots.\n",
    "ax.scatter(Xhat[:, 0], Xhat[:, 1], s=35, alpha=.55, color='tomato')\n",
    "\n",
    "ax.set_xlim(-6, 6)\n",
    "ax.set_ylim(-6, 6)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot shows the reconstructed data (red dots)  overlayed on top of the original data (blue dots), showing that each point can be represented as a linear combination of the basis function.\n",
    "\n",
    "That'll be pretty much it for the linear algebra we'll cover :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the Embedded Space\n",
    "The basis functions represent the new embedded space. That means that in that all the points also have a representation in that space. So far we looked at the representation in the full space, which resulted in a perfect reconstruction of the data. But what if we look at a smaller embedded space.\n",
    "\n",
    "To do that, let's look at a more complex example using 2 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps1 = np.random.multivariate_normal([0, 0], [[1, 0.5], [0.5, 1.2]], size=100)\n",
    "ps2 = np.random.multivariate_normal([8, 8], [[1.2, 0.5], [0.5, 1]], size=100)\n",
    "\n",
    "ps = np.vstack([ps1, ps2])\n",
    "\n",
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=120, alpha=.75)\n",
    "\n",
    "ax.set_xlim(-6, 15)\n",
    "ax.set_ylim(-6, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the SVD algorithm again (using the SAME process)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n",
    "mu = np.mean(ps, axis=0)\n",
    "X0 = ps - mu\n",
    "\n",
    "# Step 2\n",
    "U, s, V = svd(X0, full_matrices=False)\n",
    "\n",
    "# Step 3\n",
    "W = np.dot(U, np.diag(s))\n",
    "\n",
    "print ('Shape of W = (%d, %d)' % W.shape, 'Shape of V = (%d, %d)' % V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question: What would the directions clusters look like???\n",
    "Make sure you understand why it looks exactly the same (the way the arrows point is not that important)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=80, alpha=.55)\n",
    "\n",
    "for j in range(2):\n",
    "    a = 2 * np.median(np.abs(W[:, j]))  # The scalar\n",
    "\n",
    "    # Compting the \"direction\" as a function of the mean.\n",
    "    p1 = mu - a * V[j]\n",
    "    p2 = mu + a * V[j]\n",
    "    \n",
    "    dx, dy = p2 - p1\n",
    "    ax.arrow(p1[0], p1[1], dx, dy, head_width=0.5, head_length=0.5, lw=3, \n",
    "             ec='purple', fc='darkgreen')\n",
    "\n",
    "ax.set_xlim(-6, 15)\n",
    "ax.set_ylim(-6, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, instead of using the entire embedded space, let's just use one of the basis function and plot the reconstructed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=80, alpha=.55)\n",
    "\n",
    "# Reconstruction of the data from the latent-space representation\n",
    "\n",
    "# With both dimensions - if you want to see that one again.\n",
    "# Xhat = np.dot(W, V) + mu  # DON'T FORGET TO ADD THE MU\n",
    "\n",
    "# Only one vector\n",
    "Xhat = np.dot(W[:, 0].reshape(-1, 1), V[0, :].reshape(1, -1)) + mu  # DON'T FORGET TO ADD THE MU\n",
    "\n",
    "ax.scatter(Xhat[:, 0], Xhat[:, 1], s=65, alpha=.55, color='tomato')\n",
    "\n",
    "ax.set_xlim(-6, 15)\n",
    "ax.set_ylim(-6, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plot above shows the points in the embedded space (red dots) in comparison to the real space (blue dots). We can see that the location in the embedded space is basically a projection on the basis function (and it makes sense mathematically).\n",
    "\n",
    "### What is a good Embedded Space\n",
    "In this embedded space, you can see that points are close to one another if and only if they were close to one another in the real world. That is a desirable property of an embedded space.\n",
    "\n",
    "To show a bad example of an embedded let's look at using the other vector from V."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(9, 9))\n",
    "\n",
    "ax.scatter(ps[:, 0], ps[:, 1], s=80, alpha=.55)\n",
    "\n",
    "# Reconstruction of the data from the latent-space representation\n",
    "\n",
    "# With both dimensions - if you want to see that one again.\n",
    "# Xhat = np.dot(W, V) + mu  # DON'T FORGET TO ADD THE MU\n",
    "\n",
    "# Only one vector\n",
    "Xhat = np.dot(W[:, 1].reshape(-1, 1), V[1, :].reshape(1, -1)) + mu  # DON'T FORGET TO ADD THE MU\n",
    "\n",
    "ax.scatter(Xhat[:, 0], Xhat[:, 1], s=65, alpha=.55, color='tomato')\n",
    "\n",
    "ax.set_xlim(-6, 15)\n",
    "ax.set_ylim(-6, 15)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this plot points that were far from each other are now close to one another."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faces Data Set\n",
    "\n",
    "In the HW assignment you'll have to basically repeat what I've done with the 2D example using the Face data set. To help you with the assignment I'm going to do some of these things and explain what they mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt(\"data/faces.txt\", delimiter=None) # load face dataset\n",
    "\n",
    "# Running the SVD using the exact same steps.\n",
    "\n",
    "# Step 1\n",
    "mu = np.mean(X, axis=0)\n",
    "X0 = X - mu\n",
    "\n",
    "# Step 2\n",
    "U, s, V = svd(X0, full_matrices=False)\n",
    "\n",
    "# Step 3\n",
    "W = np.dot(U, np.diag(s))\n",
    "\n",
    "print ('Shape of W = (%d, %d)' % W.shape, 'Shape of V = (%d, %d)' % V.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V and W\n",
    "The part where you have to show the \"directions\" learned I will keep to the HW assignment and instead just show you the W part -- using the code from the HW assignment.\n",
    "\n",
    "In it, you are going to plot the faces as a function of their W values using only two dimensions (it's hard to plot 3d stuff and impossible to plot more than that)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(1, 1, figsize=(15, 10))\n",
    "\n",
    "idx = np.random.choice(X.shape[0], 20, replace=False)\n",
    "\n",
    "coord, params = ml.transforms.rescale(W[:,0:2]) # normalize scale of \"W\" locations\n",
    "\n",
    "for i in idx:\n",
    "    loc = (coord[i, 0], coord[i, 0] + 0.5, coord[i,1], coord[i, 1] + 0.5) # where to place the image & size\n",
    "    img = np.reshape(X[i,:], (24,24))\n",
    "    ax.imshow(img.T , cmap=\"gray\", extent=loc) # draw each image\n",
    "    \n",
    "ax.axis([-2, 2, -2, 2]) # set axis to reasonable visual scale\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hopefully you had a good random seed here and you got faces that are close to each other in the embedded space and are also similar image. If not, it is understandable. Our embedded space in this example is of 576 dimensions, this means that even if in the first 2 the images don't look alike, it is possible that adding the other dimensions will spread them apart. This is similar to the \"bad example\" in the geometric example. When we looked at the second direction points that should not have been close to each other were close tightly together, but clearly if we would have added the second dirction they will be farther apart."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Measuring Information Loss\n",
    "\n",
    "This concept can actually be quantified by measring how much information we are loosing when we use a small number of dimensions. In the HW assignment you are going to measure it with mean squared error, and plot the error as a function of the number of \"directions\" used. \n",
    "\n",
    "This \"loss\" is also very visable when looking at the images themselves. Here are two examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print ('The original images')\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 15))\n",
    "\n",
    "idx = [88, 14]\n",
    "for j in range(len(idx)):\n",
    "    i = idx[j]\n",
    "    img = np.reshape(X[i,:],(24,24))  # reshape flattened data into a 24*24 patch\n",
    "    \n",
    "    # We've seen the imshow method in the previous discussion :)\n",
    "    ax[j].imshow( img.T , cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using only 2 dimensions')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 15))\n",
    "\n",
    "idx = [88, 14]\n",
    "for j in range(len(idx)):\n",
    "    i = idx[j]\n",
    "    \n",
    "    img = np.dot(W[i, :2], V[:2]) + mu  # DON'T FORGET TO ADD THE MU\n",
    "    \n",
    "    img = np.reshape(img,(24,24))  # reshape flattened data into a 24*24 patch\n",
    "    \n",
    "    # We've seen the imshow method in the previous discussion :)\n",
    "    ax[j].imshow( img.T , cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using only 50 dimensions')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 15))\n",
    "\n",
    "idx = [88, 14]\n",
    "for j in range(len(idx)):\n",
    "    i = idx[j]\n",
    "    \n",
    "    img = np.dot(W[i, :50], V[:50]) + mu  # DON'T FORGET TO ADD THE MU\n",
    "    \n",
    "    img = np.reshape(img,(24,24))  # reshape flattened data into a 24*24 patch\n",
    "    \n",
    "    # We've seen the imshow method in the previous discussion :)\n",
    "    ax[j].imshow( img.T , cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using 300 dimensions')\n",
    "\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 15))\n",
    "\n",
    "idx = [88, 14]\n",
    "for j in range(len(idx)):\n",
    "    i = idx[j]\n",
    "    \n",
    "    img = np.dot(W[i, :300], V[:300]) + mu  # DON'T FORGET TO ADD THE MU\n",
    "    \n",
    "    img = np.reshape(img,(24,24))  # reshape flattened data into a 24*24 patch\n",
    "    \n",
    "    # We've seen the imshow method in the previous discussion :)\n",
    "    ax[j].imshow( img.T , cmap=\"gray\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more dimensions we use, the lower the loss is.\n",
    "\n",
    "### Why use smaller K then?\n",
    "If the higher K, the less information we lose, then why use a small value for dimensions? Well, this value is related directly to complexity, both time and space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also showed you a different reason, that is related to the fact that we might want to generalize to unseen data. And to do that, let's look at the recommender systems example where I want my application to recommend <b>new</b> movies to users."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie Dataset\n",
    "\n",
    "To do that, we'll use a data set where each row is unique user and each column represent a unique movie. The element i,j in the matrix is 0 if the user didn't like the movie (rating of 3 and below) and 1 if she did (rating 4 and 5).\n",
    "\n",
    "I've already prepared the data set for you. We have two files:\n",
    "\n",
    "1. data.pkl: Sparse representation of the matrix described above.\n",
    "2. movies_info.pkl: Dictionary from movie id (column id) to the name.\n",
    "\n",
    "The suffix .pkl tells you that I pickled the data which is kind of like zipped the data for Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# If python 2.x\n",
    "# sdata = pickle.load(open('./data/data.pkl', 'r'))\n",
    "# movies_info = pickle.load(open('./data/movies_info.pkl', 'r'))\n",
    "\n",
    "# If python 3.x\n",
    "sdata = pickle.load(open('./data/data.pkl', 'rb'), encoding='latin1')\n",
    "movies_info = pickle.load(open('./data/movies_info.pkl', 'rb'),  encoding='latin1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVD on the Movie Dataset\n",
    "We are going to do the exact same thing only with one difference. We will run svds instead of svd. svds is a version of svd that is suitable for sparse data. It has one extra paramters -- k. \n",
    "\n",
    "In svd() we got all the dimensions and took only the first 2, here we are going to specify directly that we only want 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "mu = sdata.mean(axis=0)\n",
    "sdata = sdata - mu\n",
    "\n",
    "U, s, V = svds(sdata, 2)\n",
    "W = np.dot(U, np.diag(s))\n",
    "\n",
    "print (W.shape, V.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Space\n",
    "\n",
    "If the embedded space in the geometric example showed directions in the 2d, what would it mean in the movies? \n",
    "\n",
    "We can't really plot it, so let's just print the top and bottom 10 movies in each direction. This will give us a clue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_sort_x = np.argsort(V[0])\n",
    "\n",
    "print ('Top 10 on the X direction')\n",
    "print ('---------------------\\n')\n",
    "for i in arg_sort_x[:10]:\n",
    "    print (movies_info[i])\n",
    "    \n",
    "print ('\\n\\n==================\\n\\n')\n",
    "    \n",
    "print ('Bottom 10 on the X direction')\n",
    "print ('---------------------\\n')\n",
    "for i in arg_sort_x[-10:]:\n",
    "    print (movies_info[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the second dimension..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arg_sort_x = np.argsort(V[1])\n",
    "\n",
    "print ('Top 10 on the X direction')\n",
    "print ('---------------------\\n')\n",
    "for i in arg_sort_x[:10]:\n",
    "    print (movies_info[i])\n",
    "    \n",
    "print ('\\n\\n==================\\n\\n')\n",
    "    \n",
    "print ('Bottom 10 on the X direction')\n",
    "print ('---------------------\\n')\n",
    "for i in arg_sort_x[-10:]:\n",
    "    print (movies_info[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that each direction captures a feature of the movies. In this example, when using only 2 dimensions the X direction captures the release date where old movies are in the bottom 10 and new movies are on the top 10. \n",
    "\n",
    "The Y direction is more open to interpertation, I think that it captures quality, where one side of the direction shows quality movies while the other one shows movies that are not really highly rated. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
